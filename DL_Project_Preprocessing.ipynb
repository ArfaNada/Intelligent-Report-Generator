{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14343391,"sourceType":"datasetVersion","datasetId":9158280}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nadaarfaoui/preprocessing-the-amazon-electronics-dataset?scriptVersionId=289227868\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# Download resources (run once)\nnltk.download('stopwords')\nnltk.download('wordnet')\n\n# Load your dataset\ndf = pd.read_csv(\"/kaggle/input/merged-amazon-electronics-dataset/merged_electronics_dataset.csv\")","metadata":{"id":"DWYyTzezStB4","outputId":"a053af0e-ecba-4ffd-eb3d-6fa895f91c84","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:10.426652Z","iopub.execute_input":"2025-12-30T12:10:10.426913Z","iopub.status.idle":"2025-12-30T12:10:14.5109Z","shell.execute_reply.started":"2025-12-30T12:10:10.426889Z","shell.execute_reply":"2025-12-30T12:10:14.509835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"id":"8M0Ytd-_XS9q","outputId":"a3dce73a-ffa7-413a-a592-ace6c1b2b031","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.512926Z","iopub.execute_input":"2025-12-30T12:10:14.513307Z","iopub.status.idle":"2025-12-30T12:10:14.545998Z","shell.execute_reply.started":"2025-12-30T12:10:14.513278Z","shell.execute_reply":"2025-12-30T12:10:14.545123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['name'] = df['name'].astype(str) \\\n                     .str.replace(r'\\(Renewed\\)', '', regex=True) \\\n                     .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True) \\\n                     .str.strip()  # remove leading/trailing spaces","metadata":{"id":"N_VgXeRFb5rH","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.546966Z","iopub.execute_input":"2025-12-30T12:10:14.547272Z","iopub.status.idle":"2025-12-30T12:10:14.58029Z","shell.execute_reply.started":"2025-12-30T12:10:14.547246Z","shell.execute_reply":"2025-12-30T12:10:14.579182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop unwanted columns\ndf = df.drop(columns=['main_category', 'sub_category'])\n# Extract brand (first word before any space or parenthesis)\ndf['brand'] = df['name'].str.extract(r'^(\\w+)')\n# Clean review_rating to keep only numeric value\ndf['review_rating'] = df['review_rating'].str.extract(r'(\\d+\\.\\d+)').astype(float)","metadata":{"id":"Ru7a6nycZvdQ","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.581614Z","iopub.execute_input":"2025-12-30T12:10:14.581917Z","iopub.status.idle":"2025-12-30T12:10:14.62274Z","shell.execute_reply.started":"2025-12-30T12:10:14.581891Z","shell.execute_reply":"2025-12-30T12:10:14.621818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values before cleaning:\\n\", df.isnull().sum(), \"\\n\")","metadata":{"id":"j-wJ5x-cXhqw","outputId":"8d1f2bcf-a404-424d-bcc0-2f2fda8928f2","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.624511Z","iopub.execute_input":"2025-12-30T12:10:14.625209Z","iopub.status.idle":"2025-12-30T12:10:14.63477Z","shell.execute_reply.started":"2025-12-30T12:10:14.625163Z","shell.execute_reply":"2025-12-30T12:10:14.633591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.dropna(subset=['review_text'])","metadata":{"id":"wdOE27BOZAKR","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.636104Z","iopub.execute_input":"2025-12-30T12:10:14.636485Z","iopub.status.idle":"2025-12-30T12:10:14.656828Z","shell.execute_reply.started":"2025-12-30T12:10:14.636456Z","shell.execute_reply":"2025-12-30T12:10:14.655603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_numeric(col):\n    col = col.astype(str).str.replace(r'[^\\d.]', '', regex=True)  # remove non-numeric chars\n    col = pd.to_numeric(col, errors='coerce')                      # convert invalids to NaN\n    return col\n\n# Apply cleaning\nfor col in ['no_of_ratings', 'discount_price', 'actual_price', 'review_rating']:\n    df[col] = clean_numeric(df[col])\n    # Fill missing values with mean (skip review_rating if you want to keep raw ratings)\n    if col != 'review_rating':\n        df[col] = df[col].fillna(df[col].mean())","metadata":{"id":"6HVrLIdXZ2wU","outputId":"f97d1102-d3ce-49a0-be08-2da6bfd9cad3","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.659831Z","iopub.execute_input":"2025-12-30T12:10:14.660663Z","iopub.status.idle":"2025-12-30T12:10:14.71201Z","shell.execute_reply.started":"2025-12-30T12:10:14.660626Z","shell.execute_reply":"2025-12-30T12:10:14.710984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values after cleaning:\\n\", df.isnull().sum(), \"\\n\")","metadata":{"id":"U-Z-S-I1ZQ9r","outputId":"f465d02c-0695-4256-de15-2a49ef04a8cc","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.713131Z","iopub.execute_input":"2025-12-30T12:10:14.713451Z","iopub.status.idle":"2025-12-30T12:10:14.722997Z","shell.execute_reply.started":"2025-12-30T12:10:14.713415Z","shell.execute_reply":"2025-12-30T12:10:14.721961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize tools\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n# Define text preprocessing function\ndef preprocess_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = text.lower()  # lowercase\n    text = re.sub(r'http\\S+|www\\S+', '', text)  # remove URLs\n    text = re.sub(r'[^a-z\\s]', '', text)  # remove punctuation and numbers\n    text = ' '.join(word for word in text.split() if word not in stop_words)  # remove stopwords\n    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())  # lemmatize words\n    return text\n\n# Apply preprocessing to review_text\ndf['cleaned_review_text'] = df['review_text'].apply(preprocess_text)\n\n# Display results\nprint(df[['review_text', 'cleaned_review_text']].head())\ndf = df.rename(columns={'review_rating': 'rating'})\n\n\n# 1️⃣ Create binary sentiment label\ndef label_sentiment(rating):\n    if rating >= 4:\n        return \"Positive\"\n    elif rating <= 2:\n        return \"Negative\"\n    else:\n        return None  # Neutral reviews will be dropped\n\ndf['sentiment'] = df['rating'].apply(label_sentiment)\n\n# 2️⃣ Drop Neutral reviews\ndf_binary = df[df['sentiment'].notnull()]\n\n# 3️⃣ Optional: check class distribution\nprint(\"Class distribution (binary):\")\nprint(df_binary['sentiment'].value_counts())\n\n# 4️⃣ Save cleaned binary dataset\ndf_binary.to_csv(\"cleaned_dataset.csv\", index=False)","metadata":{"id":"d288XawnXaDy","outputId":"0e679888-ea8b-4972-c407-8568ef4d8413","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:10:14.724172Z","iopub.execute_input":"2025-12-30T12:10:14.724437Z","iopub.status.idle":"2025-12-30T12:10:18.399032Z","shell.execute_reply.started":"2025-12-30T12:10:14.724413Z","shell.execute_reply":"2025-12-30T12:10:18.398041Z"}},"outputs":[],"execution_count":null}]}